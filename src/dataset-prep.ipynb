{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izelteker/Documents/UB Data Science/DL/HuggingFace/.env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/izelteker/Documents/UB Data Science/DL/HuggingFace/.env/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izelteker/Documents/UB Data Science/DL/HuggingFace/.env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "ds = load_dataset(\"deadprogram/clothes-with-class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m img1 = \u001b[43mds\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m2\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m text1 = ds[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m2\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "img1 = ds[\"train\"][2][\"image\"]\n",
    "text1 = ds[\"train\"][2][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_blip = (\n",
    "    ds\n",
    "    .rename_column(\"description\", \"text\")\n",
    "    .select_columns([\"image\", \"text\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': [<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1166x1750>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1166x1750>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1166x1750>],\n",
       " 'text': ['solid black off-the-shoulder blouse in a crinkled weave with wide dolman sleeves and visible seams front and back elastication around the top sleeves and hem unlined',\n",
       "  'all over pattern black short-sleeved shirt in a patterned viscose weave with a resort collar french front and straight-cut hem with short slits in the sides',\n",
       "  'solid white sleeveless blouse in woven fabric with a v-neck concealed button placket and rounded hem']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth_sample = ds_blip.shuffle(seed=42).select(range(1000))\n",
    "# Peek at the first few examples\n",
    "cloth_sample[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166, 1750)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth_sample[\"image\"][1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset\n",
    "dataset = ds_blip  # 88400 samples\n",
    "\n",
    "# first, split off test set (e.g., 10%)\n",
    "split1 = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_val_dataset = split1['train']  # 90%\n",
    "test_dataset = split1['test']        # 10%\n",
    "\n",
    "# then, split train_val into train & validation (e.g., 80/20 of 90%)\n",
    "split2 = train_val_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split2['train']       # 72%\n",
    "val_dataset = split2['test']          # 18%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "final_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'text'],\n",
      "        num_rows: 62928\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'text'],\n",
      "        num_rows: 15732\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'text'],\n",
      "        num_rows: 8740\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(final_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (26/26 shards): 100%|██████████| 62928/62928 [01:32<00:00, 678.01 examples/s]\n",
      "Saving the dataset (7/7 shards): 100%|██████████| 15732/15732 [00:36<00:00, 426.37 examples/s]\n",
      "Saving the dataset (4/4 shards): 100%|██████████| 8740/8740 [00:24<00:00, 350.75 examples/s] \n"
     ]
    }
   ],
   "source": [
    "#final_dataset.save_to_disk(\"cloth_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(img1, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs, max_length=80)\n",
    "caption = processor.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[43mimg1\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'img1' is not defined"
     ]
    }
   ],
   "source": [
    "type(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a woman ' s long sleeved top with a scoop neck\n"
     ]
    }
   ],
   "source": [
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'solid dark blue fitted top in soft stretch jersey with a wide neckline and long sleeves'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
